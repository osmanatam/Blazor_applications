{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI Platform workshop.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osmanatam/Blazor_applications/blob/master/AI_Platform_workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_igd9S2BL-NT",
        "colab_type": "text"
      },
      "source": [
        "## What is it?\n",
        "This notebook demonstrates how to train a machine learning model with TensorFlow by using [AI Platform](https://cloud.google.com/ai-platform/), a serverless service by Google Cloud Platform for training and batch or online prediction. As this is a paid service, you may want to use [price calculator](https://cloud.google.com/products/calculator/) to estimate how much does your workload cost.\n",
        "\n",
        "## By M. Yusuf Sarıgöz\n",
        "I'm co-founder & AI engineer at [AI Labs](https://ailabs.com.tr), a Turkish startup revolutionizing industries with an AI-first approach, [Google Developer Expert on Machine Learning](https://developers.google.com/community/experts/directory/profile/profile-m._yusuf_sar_C4_B1g_C3_B6z), and lead at [TensorFlow Turkey](https://kommunity.com/tensorflow-turkey) community. You can follow me on [Twitter](https://twitter.com/myusufsarigoz), [GitHub](https://github.com/monatis) or connect me on [LinkedIn](https://www.linkedin.com/in/yusuf-sar%C4%B1g%C3%B6z-4bb826ba/).\n",
        "\n",
        "## Getting Started\n",
        "Below, you need to authenticate Google Cloud command line tools to access your Google Cloud services. To do so, run this cell, click on the link in the output preview, choose your Google Cloud account in the new tab, and finally copy and past the code below to complete the login process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jESsH81RN4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gcloud auth login"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cGlOYIrOltx",
        "colab_type": "text"
      },
      "source": [
        "## Set Project\n",
        "Now, you need to set the id of the project you want to associate the resources with. You may need to create a new project and set the billing account on Google Cloud Console before running the command below. Then, replace `aiml-dev-2020` with your own project ID and run it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QamgHFJqSLIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gcloud config set project aiml-dev-2020"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iBOAbM0PyGT",
        "colab_type": "text"
      },
      "source": [
        "## Enable Services\n",
        "Run the three cells below to enable [Compute Engine](https://cloud.google.com/compute/), [Cloud Storage](https://cloud.google.com/products/storage/) and AI Platform (previously ML Engine) services. We will keep our dataset and models in Cloud Storage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nTKaDrZSLHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gcloud services enable compute.googleapis.com"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxAE38gxV-7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gcloud services enable storage-component.googleapis.com"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La0_dDHpWKYF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gcloud services enable ml.googleapis.com"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alkIZvO7RaGs",
        "colab_type": "text"
      },
      "source": [
        "## Set Environment Variables\n",
        "use `%env` magic to export some environment variables to use in subsequent  commands. If you want to replicate these commands in your workstation, you can use familiar `export` command to set environment variables.\n",
        "\n",
        "Here, `RUNTIME_VERSION` refers to the version of the runtime that AI Platform will run our code on, and `PYTHON_VERSION` refers to the version of Python that AI Platform pass our code to. `REGION` may be of the regions supported by AI Platform, and `BUCKET_NAME` is the name of the Google Cloud Storage bucket to storage dataset in. A bucket with this name will be created further below. As any bucket name should be universally unique, please change it from `ailabscomtr19` to something else you own --a domain you manage, for example. Additionally, change the value of `PROJECT_ID` environment variable to the project ID you set previously under the `Set Project` section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFusv54oXXfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%env RUNTIME_VERSION=1.14"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xix9w26hd-Rp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%env PYTHON_VERSION=3.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRK4XK6reRb3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%env REGION=us-central1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xcF3knmfaOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%env BUCKET_NAME=ailabscomtr19"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwabqVVE4psh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%env PROJECT_ID=aiml-dev-2020"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjWtRNPYUgip",
        "colab_type": "text"
      },
      "source": [
        "## Create Bucket\n",
        "This command creates a bucket with the name you set in the previous section. If you try to run it multiple times, you may get an `Service Exception` stating that a bucket with name already exists --you may safely ignore it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZfg8uYSOGbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gsutil mb gs://${BUCKET_NAME}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DZq4JrnVshL",
        "colab_type": "text"
      },
      "source": [
        "## Prepare Dataset\n",
        "In this section, you will prepare the dataset to upload to Google Cloud Storage. In this sample, we will use [Cats And Dogs Filtered](https://bit.ly/33n6FcG), a small dataset for training purposes. It contains 1000 cat images and 1000 dogs images in the training set and 500 images for each one of the two categories in the validation set.\n",
        "\n",
        "\n",
        "First, we will download it from a shortened URL and extract to a directory. Then we will set environment variables pointing where it resides in our local filesystem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OV9nn3xiOsE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "url = 'https://bit.ly/33n6FcG'\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs_filtered.zip', origin=url, extract=True)\n",
        "path_to_zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EmgJum9P2e1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%env TRAIN_DIR=/root/.keras/datasets/cats_and_dogs_filtered/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4NPeL9QQgcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%env VAL_DIR=/root/.keras/datasets/cats_and_dogs_filtered/validation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNZSOjeDbORH",
        "colab_type": "text"
      },
      "source": [
        "## Upload Dataset\n",
        "Set environment variables where we upload dataset on Google Cloud Storage. Change `ailabscomtr19` to your own bucket name that you created previously. Then, use `gsutil cp` command to upload the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CalfqJ-yTLlT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%env GCS_TRAIN_DIR=gs://ailabscomtr19/datasets/cats_and_dogs/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovbdWiLAUPrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%env GCS_VAL_DIR=gs://ailabscomtr19/datasets/cats_and_dogs/validation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KmotFdUQ-oC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gsutil -m cp -r ${TRAIN_DIR} ${GCS_TRAIN_DIR}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8snEARSUgrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gsutil -m cp -r ${VAL_DIR} ${GCS_VAL_DIR}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BH1o_JJd2w4",
        "colab_type": "text"
      },
      "source": [
        "## Create Service Account\n",
        "In this section, we will create a service account with necessary roles to manage AI Platform and Google Cloud Storage. We will store credentials in `key.json` file and then export `GOOGLE_APPLICATION_CREDENTIALS` environment variable poing to this file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tvj8B2kfpUF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%env SERVICE_ACCOUNT_NAME=aiplatacc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zenYpvUZfz1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gcloud iam service-accounts create ${SERVICE_ACCOUNT_NAME} --display-name=\"Service Account for ai-platform\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5Eva83agNrQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gcloud projects add-iam-policy-binding ${PROJECT_ID} --member serviceAccount:${SERVICE_ACCOUNT_NAME}@${PROJECT_ID}.iam.gserviceaccount.com --role roles/ml.developer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNhWE67_gaes",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gcloud projects add-iam-policy-binding ${PROJECT_ID} --member serviceAccount:${SERVICE_ACCOUNT_NAME}@${PROJECT_ID}.iam.gserviceaccount.com --role roles/storage.objectAdmin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qga0GwV5gp5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%env GOOGLE_APPLICATION_CREDENTIALS=/content/key.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxRNgAc0iH05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gcloud iam service-accounts keys create ${GOOGLE_APPLICATION_CREDENTIALS} --iam-account ${SERVICE_ACCOUNT_NAME}@${PROJECT_ID}.iam.gserviceaccount.com"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F92Trxf8e0mS",
        "colab_type": "text"
      },
      "source": [
        "## Clone Code Repo\n",
        "Use `git` to clone the [repository](https://github.com/monatis/aiplatform-workshop) containing a very simple VGG-like model architecture and training logic. Please note that accuracy and performance is not a priority for the purpose of this sample, instead I aim at providing a concise code to focus more on the use of AI Platform."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWjNeIXViNGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/monatis/aiplatform-workshop.git trainer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IOVizzKhdGK",
        "colab_type": "text"
      },
      "source": [
        "## Train Locally\n",
        "Before running `trainer` in the cloud, train it one epoch locally  for sanity check. You may run this command multiple times, and it will not be charged."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NU2PJKANizwr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gcloud ai-platform local train --module-name=trainer.task --package-path=./trainer -- --train_dir ${TRAIN_DIR} --validation_dir ${VAL_DIR} --job-dir ./ --epochs 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x9KNFqfsk0M",
        "colab_type": "text"
      },
      "source": [
        "## Train in the Cloud\n",
        "Finally, we will submit our training job to AI Platform to train the model in the cloud. To do so, we will export some environment variables to control where our training job will be executed.\n",
        "\n",
        "Change `MODEL_DIR` to some path in your own GCS bucket. You may also want to update `MODEL_NAME` and `JOB_NAME` to reflect your own model. When the training job is running, you should be able to see logs streamed to the output preview. When you ge the log \"Task completed successfully,\" you may understand that training is done and simply interrupt execution of the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFGv69JKjnWQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%env TIER=BASIC_GPU\n",
        "%env MODEL_NAME=\"vgg8_cats_and_dogs\"\n",
        "%env PACKAGE_PATH=./trainer\n",
        "%env MODEL_DIR=gs://ailabscomtr19/vgg8_cats_and_dogs/model\n",
        "d=!date +%Y%m%d%H%M%S\n",
        "d=str(d[0])\n",
        "%env JOB_NAME=job_$d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pptKGIu3f55d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gcloud ai-platform jobs submit training ${JOB_NAME} --job-dir=${MODEL_DIR} --runtime-version=${RUNTIME_VERSION} --region=${REGION} --scale-tier=${TIER} --module-name=trainer.task --package-path=${PACKAGE_PATH} --python-version=${PYTHON_VERSION} --stream-logs -- --train_dir ${GCS_TRAIN_DIR} --validation_dir ${GCS_VAL_DIR} --epochs 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCRIly0xqsz1",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion\n",
        "Congrats! You trained your first TensorFlow model in the cloud with AI Platform. Now, you may want to list files in `MODEL_DIR` by executing the cell below. You may download the model file to use for inference, or you may choose to serve it as a web API with AI Platform. I'm planning to publish a separate notebook about it. You may follow me on my social media accounts listed in the first section of this notebook to get updates about new notebooks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bVK9_5wrwlC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gsutil ls -r ${MODEL_DIR}/**"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}